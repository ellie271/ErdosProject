{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7384e4",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "In this notebook, we explore LogisticRegression to predict if PA forms will be approved. We will be using Drug, BIN, Reject Code, and flags for Tried & Failed, Contraindication, and Correct Diagnosis for prediction. We also use LASSO to explore variable importance. First, we import the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1453a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f3b6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "## Logistic Regression, Lasso for feature selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "## Import splits and metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af287118",
   "metadata": {},
   "source": [
    "Now, we create our train test split, making sure to stratify on PA approval. We choose our test size to be 20% of the available data, and use the same random seed in all other model notebooks. We will use the test set after choosing our final model (and not in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf8bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cleaned CSV (no date information)\n",
    "cmm_pa_clf_read = pd.read_csv(\"../Data/cmm_pa_clf.csv\",index_col = 0)\n",
    "\n",
    "#drop pa_approved for the predictors, only use it for target.\n",
    "cmm_pa_clf_data = cmm_pa_clf_read.drop(columns = 'pa_approved').copy()\n",
    "cmm_pa_clf_target = cmm_pa_clf_read['pa_approved'].copy()\n",
    "X_train,X_test,y_train,y_test= train_test_split(cmm_pa_clf_data, cmm_pa_clf_target, test_size = 0.2, \n",
    "                                             random_state = 10475, shuffle = True,\n",
    "                                            stratify = cmm_pa_clf_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42721a96",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "Our baseline model will be predicting all claims will have PA approved, as the majority of claims are approved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fffc151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.445 percent of the training set has PA approved, so our baseline model will predict all PA forms are approved.\n"
     ]
    }
   ],
   "source": [
    "if y_train.value_counts(normalize=True)[1]>.5:\n",
    "    print(np.round(y_train.value_counts(normalize=True)[1]*100,3),\"percent of the training set has PA approved, so\",\n",
    "          \"our baseline model will predict all PA forms are approved.\")\n",
    "else:\n",
    "    print(np.round(y_train.value_counts(normalize=True)[1]*100,3),\"percent of the training set has PA approved, so\",\n",
    "          \"our baseline model will predict all PA forms are declined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ba226",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "Here, we use Lasso for feature selection. Note that this identifies reject code, drug C, contraindiation, tried and failed, and bin 417740 as important, the same variables that showed up at the top of the decision tree in the Decision Tree notebook. However, all the variables last a similar amount as alpha increases, so we will keep them all moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cea0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct_diagnosis</th>\n",
       "      <th>tried_and_failed</th>\n",
       "      <th>contraindication</th>\n",
       "      <th>drug_B</th>\n",
       "      <th>drug_C</th>\n",
       "      <th>bin_417614</th>\n",
       "      <th>bin_417740</th>\n",
       "      <th>bin_999001</th>\n",
       "      <th>reject_code_75.0</th>\n",
       "      <th>reject_code_76.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.038008</td>\n",
       "      <td>0.112558</td>\n",
       "      <td>-0.243912</td>\n",
       "      <td>-0.094623</td>\n",
       "      <td>-0.185767</td>\n",
       "      <td>0.068818</td>\n",
       "      <td>-0.001204</td>\n",
       "      <td>0.092958</td>\n",
       "      <td>0.493082</td>\n",
       "      <td>0.373351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.037952</td>\n",
       "      <td>0.112522</td>\n",
       "      <td>-0.243856</td>\n",
       "      <td>-0.094517</td>\n",
       "      <td>-0.185687</td>\n",
       "      <td>0.068717</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>0.092821</td>\n",
       "      <td>0.492972</td>\n",
       "      <td>0.373283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>0.037392</td>\n",
       "      <td>0.112160</td>\n",
       "      <td>-0.243298</td>\n",
       "      <td>-0.093457</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.067698</td>\n",
       "      <td>-0.001976</td>\n",
       "      <td>0.091454</td>\n",
       "      <td>0.491876</td>\n",
       "      <td>0.372603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>0.031794</td>\n",
       "      <td>0.108543</td>\n",
       "      <td>-0.237719</td>\n",
       "      <td>-0.082734</td>\n",
       "      <td>-0.176899</td>\n",
       "      <td>0.057245</td>\n",
       "      <td>-0.009288</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>0.480896</td>\n",
       "      <td>0.366339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072333</td>\n",
       "      <td>-0.181774</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.096685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.042815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386318</td>\n",
       "      <td>0.282130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.000000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.000000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.000000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.000000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.000000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            correct_diagnosis  tried_and_failed  contraindication    drug_B  \\\n",
       "0.000001             0.038008          0.112558         -0.243912 -0.094623   \n",
       "0.000010             0.037952          0.112522         -0.243856 -0.094517   \n",
       "0.000100             0.037392          0.112160         -0.243298 -0.093457   \n",
       "0.001000             0.031794          0.108543         -0.237719 -0.082734   \n",
       "0.010000             0.000000          0.072333         -0.181774 -0.000000   \n",
       "0.100000             0.000000          0.000000         -0.000000  0.000000   \n",
       "1.000000             0.000000          0.000000         -0.000000  0.000000   \n",
       "5.000000             0.000000          0.000000         -0.000000  0.000000   \n",
       "10.000000            0.000000          0.000000         -0.000000  0.000000   \n",
       "25.000000            0.000000          0.000000         -0.000000  0.000000   \n",
       "50.000000            0.000000          0.000000         -0.000000  0.000000   \n",
       "100.000000           0.000000          0.000000         -0.000000  0.000000   \n",
       "\n",
       "              drug_C  bin_417614  bin_417740  bin_999001  reject_code_75.0  \\\n",
       "0.000001   -0.185767    0.068818   -0.001204    0.092958          0.493082   \n",
       "0.000010   -0.185687    0.068717   -0.001275    0.092821          0.492972   \n",
       "0.000100   -0.184887    0.067698   -0.001976    0.091454          0.491876   \n",
       "0.001000   -0.176899    0.057245   -0.009288    0.076860          0.480896   \n",
       "0.010000   -0.096685    0.000000   -0.042815    0.000000          0.386318   \n",
       "0.100000   -0.000000   -0.000000   -0.000000    0.000000          0.000000   \n",
       "1.000000   -0.000000   -0.000000   -0.000000    0.000000          0.000000   \n",
       "5.000000   -0.000000   -0.000000   -0.000000    0.000000          0.000000   \n",
       "10.000000  -0.000000   -0.000000   -0.000000    0.000000          0.000000   \n",
       "25.000000  -0.000000   -0.000000   -0.000000    0.000000          0.000000   \n",
       "50.000000  -0.000000   -0.000000   -0.000000    0.000000          0.000000   \n",
       "100.000000 -0.000000   -0.000000   -0.000000    0.000000          0.000000   \n",
       "\n",
       "            reject_code_76.0  \n",
       "0.000001            0.373351  \n",
       "0.000010            0.373283  \n",
       "0.000100            0.372603  \n",
       "0.001000            0.366339  \n",
       "0.010000            0.282130  \n",
       "0.100000            0.000000  \n",
       "1.000000            0.000000  \n",
       "5.000000            0.000000  \n",
       "10.000000           0.000000  \n",
       "25.000000           0.000000  \n",
       "50.000000           0.000000  \n",
       "100.000000          0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [0.000001,.00001,.0001,.001,.01,.1,1,5,10,25,50,100]\n",
    "features = X_train.columns.tolist()\n",
    "\n",
    "## make coefficient holder\n",
    "coefs = np.zeros((len(alphas), len(features)))\n",
    "\n",
    "## Loop through alphas\n",
    "for i in range(len(alphas)):\n",
    "    ## make lasso model\n",
    "    lasso = Lasso(alpha=alphas[i], max_iter=10000000)\n",
    "    \n",
    "    \n",
    "    ## fit model\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    ## record coefs\n",
    "    coefs[i,:] = lasso.coef_\n",
    "pd.DataFrame(coefs, index=alphas, columns=features)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6722a3",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "We perform 5-fold cross validation to explore the accuracy rate and roc_auc as we change C, changing the regularization strength for LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3c95fad",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.71 MiB for an array with shape (355808, 1) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ff475eaecb65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m#save scores for train subset and validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mcv_accs_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mcv_aucs_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         scores = safe_sparse_dot(X, self.coef_.T,\n\u001b[0m\u001b[0;32m    290\u001b[0m                                  dense_output=True) + self.intercept_\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.71 MiB for an array with shape (355808, 1) and data type float64"
     ]
    }
   ],
   "source": [
    "#kfold cross validation, and C penalty range\n",
    "kfold = StratifiedKFold(5, shuffle=True, random_state=10475)\n",
    "Cs = [0.000001,.00001,.0001,.001,.01,.1,1,5,10,25,50,100]\n",
    "\n",
    "#matrices to hold accuracy and ROC-AUC scores for validation sets and train subsets\n",
    "cv_accs = np.zeros((5, len(Cs)+1))\n",
    "cv_accs_train = np.zeros((5, len(Cs)+1))\n",
    "cv_aucs = np.zeros((5, len(Cs)+1))\n",
    "cv_aucs_train = np.zeros((5, len(Cs)+1))\n",
    "\n",
    "\n",
    "i = 0\n",
    "#loop through the cross-validation subsets\n",
    "for train_index, test_index in  kfold.split(X_train, y_train):\n",
    "    X_train_train = X_train.iloc[train_index]\n",
    "    X_holdout = X_train.iloc[test_index]\n",
    "    y_train_train  =  y_train.iloc[train_index]\n",
    "    y_holdout = y_train.iloc[test_index]\n",
    "    \n",
    "    #baseline performance on the train and validation sets\n",
    "    cv_accs_train[i,0] = accuracy_score(y_train_train, np.ones(len(y_train_train)))\n",
    "    cv_aucs_train[i,0] = roc_auc_score(y_train_train, np.ones(len(y_train_train)))\n",
    "\n",
    "    cv_accs[i,0] = accuracy_score(y_holdout, np.ones(len(y_holdout)))\n",
    "    cv_aucs[i,0] = roc_auc_score(y_holdout, np.ones(len(y_holdout)))    \n",
    "    \n",
    "    j = 1\n",
    "    #loop through the trees with varying depth\n",
    "    for c in Cs:\n",
    "        logreg=LogisticRegression(C=c)\n",
    "        logreg.fit(X_train_train, y_train_train)\n",
    "        \n",
    "        #save scores for train subset and validation set\n",
    "        cv_accs_train[i,j] = accuracy_score(y_train_train, logreg.predict(X_train_train))\n",
    "        cv_aucs_train[i,j] = roc_auc_score(y_train_train, logreg.predict_proba(X_train_train)[:,1])\n",
    "        \n",
    "        cv_accs[i,j] = accuracy_score(y_holdout, logreg.predict(X_holdout))\n",
    "        cv_aucs[i,j] = roc_auc_score(y_holdout, logreg.predict_proba(X_holdout)[:,1])\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy scores:\")\n",
    "print(\"For training subsets:\",np.mean(cv_accs_train,axis=0))\n",
    "print(\"For the validation subsets:\",np.mean(cv_accs,axis=0))\n",
    "print(\"The ROC-AUC scores:\")\n",
    "print(\"For training subsets:\",np.mean(cv_aucs_train,axis=0))\n",
    "print(\"For the validation subsets:\",np.mean(cv_aucs,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.argmax(np.mean(cv_accs,axis=0)==0):\n",
    "    print(\"None of these models beat our baseline model on accuracy.\")\n",
    "else:\n",
    "    \n",
    "    print(\"The model with the best accuracy had a C value of\",Cs[np.argmax(np.mean(cv_accs,axis=0))-1])\n",
    "if np.argmax(np.mean(cv_accs,axis=0)==0):\n",
    "    print(\"None of these models beat our baseline model on ROC AUC score.\")\n",
    "else:\n",
    "    #if we change the depth range, this will automatically change, depth[0] is the minimum depth, the -1 compensates for the baseline at position 0\n",
    "    print(\"The model with the best ROC AUC score had a C value of\",Cs[np.argmax(np.mean(cv_aucs,axis=0))-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976818d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this plots the average accuracy and accuracy for the CV subsets as a function of the maximum depth\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "\n",
    "#plot CV accuracies (one outside loop for non-repeating legend)\n",
    "plt.plot(Cs,cv_accs[1,1:],'o',color='gray',alpha=.7,label='Cross Validation Subsets') \n",
    "for i in range(1,5):\n",
    "    plt.plot(Cs,cv_accs[i,1:],'o',color='gray',alpha=.7,label='_no_legend_')\n",
    "    \n",
    "#Plot average CV accuracy \n",
    "plt.plot(Cs,np.mean(cv_accs[:,1:], axis=0),\n",
    "         '-o',color='red',\n",
    "         label=\"Average\")\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"C value\", fontsize=16)\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"CV Accuracy\", fontsize=16)\n",
    "\n",
    "plt.xticks(Cs, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## this plots the average ROC-AUC and ROC-AUC for the CV subsets as a function of the maximum depth\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "#plot CV ROC-AUC scores (one outside loop for non-repeating legend)\n",
    "plt.plot(Cs,cv_aucs[1,1:],'o',color='gray',alpha=.7,label='Cross Validation Subsets') \n",
    "for i in range(1,5):\n",
    "    plt.plot(Cs,cv_aucs[i,1:],'o',color='gray',alpha=.7,label='_no_legend_')\n",
    "    \n",
    "#Plot average CV accuracy \n",
    "plt.plot(Cs,np.mean(cv_aucs[:,1:], axis=0),\n",
    "         '-o',color='blue',\n",
    "         label=\"Average\")\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.xlabel(\"C value\", fontsize=16)\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"ROC-AUC Score\", fontsize=16)\n",
    "\n",
    "plt.xticks(Cs, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e277bc1",
   "metadata": {},
   "source": [
    "Based on our cross-validation, our chosen Logistic Regression model will have $C=0.1$. We look at the ROC-AUC score and accuaracy score on the whole train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(C=.1)\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=logreg.predict(X_train)\n",
    "\n",
    "print(\"For the chosen logistic regression model, the accuracy on the training set is\",accuracy_score(y_train,pred))\n",
    "print(\"For the chosen logistic regression model, the ROC-AUC on the training set is\",roc_auc_score(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ced2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
