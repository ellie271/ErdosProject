{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86de9e65",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "We are using the XGBoost package (https://xgboost.readthedocs.io/en/latest/index.html , version 1.5.0) in this notebook .We will use XGBClassifier to solve the classification problem which we predict wether a PA form will be approved base on information provided on the PA form. Our data features are 'correct_diagnosis', 'tried_and_failed', 'contraindication', 'drug'(drug type), 'bin'(payer id),'reject_code', which are all categorical. Our label will be 'pa_approved'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3876d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pacakges\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73e960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "cmm_pa_clf_read = pd.read_csv(\"../Data/cmm_pa_clf.csv\",index_col = 0)\n",
    "cmm_pa_clf_data = cmm_pa_clf_read.drop(columns = 'pa_approved').copy()\n",
    "cmm_pa_clf_target = cmm_pa_clf_read['pa_approved'].copy()\n",
    "X_train,X_test,Y_train,Y_test= train_test_split(cmm_pa_clf_data, cmm_pa_clf_target, test_size = 0.2, \n",
    "                                             random_state = 10475, shuffle = True,\n",
    "                                            stratify = cmm_pa_clf_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae3f5f",
   "metadata": {},
   "source": [
    "## Baseline:\n",
    "We predoct that all PA form will be approved. In this case the true positive rate = false positive rate = 1, the ROC-AUC score of our baseline model is 0.5. The error of this predictor is 100-73.445 = 26.555."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2387007",
   "metadata": {},
   "source": [
    "## XGBClassifier\n",
    "We will using GBTree booster; our learning objective (objective to solve during the optimization problem) is  logloss for binary regression; we will tune our parameters based on the accuracy and roc-auc scores.\n",
    "\n",
    "We will explore the performance of the algorithm for:  \n",
    "tree_method to be 'approx' or 'hist'  \n",
    "max_depeth to be 1, 2, or 3  \n",
    "subsample rate to be 0.5, 0.8, 1  \n",
    "n_estimators up to 90  \n",
    "eta to be 0.1,0.5,1,3,7,10  \n",
    "\n",
    "We are going to use the GridSearchCV from sklearn to perform hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b170ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found based on the parameter set:\n",
      "\n",
      "{'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False}\n",
      "Grid scores on parameter set:\n",
      "\n",
      "0.802 (+/-0.008) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.800 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.800 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.800 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.800 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.800 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.000) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.814 (+/-0.001) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.533 (+/-0.272) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.546 (+/-0.281) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.546 (+/-0.280) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.616 (+/-0.004) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.616 (+/-0.004) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.616 (+/-0.004) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.731 (+/-0.017) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.735 (+/-0.003) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.735 (+/-0.003) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.726 (+/-0.019) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.726 (+/-0.022) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.726 (+/-0.022) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.633 (+/-0.122) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.548 (+/-0.328) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.704 (+/-0.056) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.636 (+/-0.358) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.628 (+/-0.344) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.628 (+/-0.344) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.734 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.734 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.734 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.734 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.734 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.734 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.531 (+/-0.275) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.433 (+/-0.199) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.624 (+/-0.256) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.653 (+/-0.081) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.371 (+/-0.242) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.371 (+/-0.242) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.293 (+/-0.321) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.213 (+/-0.001) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.213 (+/-0.001) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.213 (+/-0.001) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.213 (+/-0.001) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.213 (+/-0.001) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.417 (+/-0.302) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.573 (+/-0.371) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.418 (+/-0.303) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.722 (+/-0.012) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.649 (+/-0.309) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.649 (+/-0.309) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.359 (+/-0.375) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.266 (+/-0.000) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found based on the parameter set:\n",
      "\n",
      "{'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False}\n",
      "Grid scores on parameter set:\n",
      "\n",
      "0.871 (+/-0.003) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.871 (+/-0.003) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.872 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.872 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.872 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.872 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 0.5, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.878 (+/-0.002) for {'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.605 (+/-0.286) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.677 (+/-0.170) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.649 (+/-0.267) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.717 (+/-0.006) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.716 (+/-0.004) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.716 (+/-0.004) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.705 (+/-0.229) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.787 (+/-0.005) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.786 (+/-0.011) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.690 (+/-0.209) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.733 (+/-0.129) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.733 (+/-0.129) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.558 (+/-0.100) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.596 (+/-0.118) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.612 (+/-0.134) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.584 (+/-0.112) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.581 (+/-0.178) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.581 (+/-0.178) for {'booster': 'gbtree', 'eta': 3, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.500 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.500 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.500 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.500 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.500 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.500 (+/-0.000) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.372 (+/-0.183) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.300 (+/-0.146) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.435 (+/-0.157) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.455 (+/-0.045) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.323 (+/-0.176) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.323 (+/-0.176) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.254 (+/-0.186) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.208 (+/-0.004) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.208 (+/-0.004) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.208 (+/-0.004) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.208 (+/-0.004) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.208 (+/-0.004) for {'booster': 'gbtree', 'eta': 7, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.560 (+/-0.001) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.560 (+/-0.001) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.560 (+/-0.001) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.560 (+/-0.001) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.560 (+/-0.001) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.560 (+/-0.001) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.432 (+/-0.170) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.512 (+/-0.167) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.438 (+/-0.165) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.581 (+/-0.081) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.518 (+/-0.158) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.518 (+/-0.158) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 2, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.404 (+/-0.120) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.403 (+/-0.003) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.385 (+/-0.075) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.403 (+/-0.003) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.8, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "0.403 (+/-0.003) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False} \n",
      "\n",
      "0.403 (+/-0.003) for {'booster': 'gbtree', 'eta': 10, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'hist', 'use_label_encoder': False} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'booster': ['gbtree'], 'objective': ['binary:logistic'], 'max_depth': [1,2,3],\n",
    "             'subsample': [0.5,0.8,1], 'tree_method': ['approx','hist'],\n",
    "             'n_estimators': [90], 'eta': [0.1,0.5,1,3,7,10],'use_label_encoder': [False]}\n",
    "scores = ['accuracy','roc_auc']\n",
    "xgb_clf= xgb.XGBClassifier(eval_metric = 'auc')\n",
    "skf = StratifiedKFold(n_splits=5,random_state=10475, shuffle=True)\n",
    "for scr in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % scr)\n",
    "    print()\n",
    "    clf_tun = GridSearchCV(xgb_clf, tuned_parameters, scoring=\"%s\" % scr,cv = skf)\n",
    "    clf_tun.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found based on the parameter set:\")\n",
    "    print()\n",
    "    print(clf_tun.best_params_)\n",
    "    print(\"Grid scores on parameter set:\")\n",
    "    print()\n",
    "    means = clf_tun.cv_results_[\"mean_test_score\"]\n",
    "    stds = clf_tun.cv_results_[\"std_test_score\"]\n",
    "    for mean, std, params in zip(means, stds, clf_tun.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r \\n\" % (mean, std * 2, params))\n",
    "    print()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c2b9f",
   "metadata": {},
   "source": [
    "From the detailed performance matrix, we can notice that quite a lot of algorithm have similar performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0d50f",
   "metadata": {},
   "source": [
    "Best parameters set found based on the parameter set:\n",
    "\n",
    "{'booster': 'gbtree', 'eta': 1, 'max_depth': 1, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 0.5, 'tree_method': 'hist', 'use_label_encoder': False}\n",
    "\n",
    "Best parameters set found based on the parameter set:\n",
    "\n",
    "{'booster': 'gbtree', 'eta': 1, 'max_depth': 3, 'n_estimators': 90, 'objective': 'binary:logistic', 'subsample': 1, 'tree_method': 'approx', 'use_label_encoder': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c76232",
   "metadata": {},
   "source": [
    "Now we would like to re-fit our model using the two set of parameters found above on the entire training set, and see the performance on the test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c76c4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb693eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.49      0.58    118105\n",
      "           1       0.83      0.93      0.88    326655\n",
      "\n",
      "    accuracy                           0.81    444760\n",
      "   macro avg       0.78      0.71      0.73    444760\n",
      "weighted avg       0.80      0.81      0.80    444760\n",
      "\n",
      "Accuacy score of this set of parameter is:  0.8141739365050814 \n",
      "\n",
      "ROC-AUC score of this set of parameter is:  0.7101437502297483 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf= xgb.XGBClassifier(booster = 'gbtree',objective = 'binary:logistic',max_depth = 1,subsample = 0.5,\n",
    "                           tree_method = 'hist', n_estimators= 90,\n",
    "                           eta = 1, use_label_encoder=False,eval_metric = 'error')\n",
    "xgb_clf.fit(X_train,Y_train,eval_set = [(X_train,Y_train)],verbose = False)\n",
    "Y_pred = xgb_clf.predict(X_train)\n",
    "print(classification_report(Y_train, Y_pred))\n",
    "print('Accuacy score of this set of parameter is: ', accuracy_score(Y_train, Y_pred),'\\n')\n",
    "print('ROC-AUC score of this set of parameter is: ', roc_auc_score(Y_train, Y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7dce096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10, 10))\n",
    "results = xgb_clf.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "plt.plot(x_axis, results['validation_0']['error'], label='Train_all')\n",
    "plt.ylabel('error')\n",
    "plt.title('XGBoost error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643d755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59    118105\n",
      "           1       0.84      0.93      0.88    326655\n",
      "\n",
      "    accuracy                           0.81    444760\n",
      "   macro avg       0.77      0.72      0.74    444760\n",
      "weighted avg       0.80      0.81      0.80    444760\n",
      "\n",
      "Accuacy score of this set of parameter is:  0.8141851785232485 \n",
      "\n",
      "ROC-AUC score of this set of parameter is:  0.715330072034963 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf_r= xgb.XGBClassifier(booster = 'gbtree',objective = 'binary:logistic',max_depth = 3,subsample = 1,\n",
    "                           tree_method = 'approx', n_estimators= 90,\n",
    "                           eta = 1, use_label_encoder=False,eval_metric = 'auc')\n",
    "xgb_clf_r.fit(X_train,Y_train,eval_set = [(X_train,Y_train)],verbose = False)\n",
    "Y_pred = xgb_clf_r.predict(X_train)\n",
    "print(classification_report(Y_train, Y_pred))\n",
    "print('Accuacy score of this set of parameter is: ', accuracy_score(Y_train, Y_pred),'\\n')\n",
    "print('ROC-AUC score of this set of parameter is: ', roc_auc_score(Y_train, Y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48ec279e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(10, 10))\n",
    "results = xgb_clf_r.evals_result()\n",
    "epochs = len(results['validation_0']['auc'])\n",
    "x_axis = range(0, epochs)\n",
    "plt.plot(x_axis, results['validation_0']['auc'], label='Train_all')\n",
    "plt.ylabel('roc_auc')\n",
    "plt.title('XGBoost roc_auc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f82dab",
   "metadata": {},
   "source": [
    "Sice the ROC-AUC scores have ~ 15% difference for the training and testing data, there might be overfit.   \n",
    "The accuracy score are similar tough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a6a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
